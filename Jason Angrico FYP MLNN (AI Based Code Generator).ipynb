{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16007500",
   "metadata": {},
   "source": [
    "# Final Year Project \n",
    "#### Topic: MLNN (AI Code Generator)\n",
    "### Made By: Jason Angrico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe9650a",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab66df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"codeDatasetTest.txt\", \"r\", encoding=\"utf-8\")\n",
    "fileEntries = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67dcce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# write a python function to add two user provided numbers and return the sum\\n',\n",
       " 'def add_two_numbers(num1, num2):\\n',\n",
       " '    sum = num1 + num2\\n',\n",
       " '    return sum\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '# write a python program to add two numbers \\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileEntries[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c698fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init an empty dictionary and temp dictionary; QnADict and tempDict respectively\n",
    "QnADict = []\n",
    "tempDict = None\n",
    "\n",
    "# Loop through the file, if entry starts with a # indicating a new question:\n",
    "for entry in fileEntries:\n",
    "    if entry.startswith(\"#\"):\n",
    "        # If tempDict is not empty (contains the previous QnA)\n",
    "        if tempDict:\n",
    "            # Join the the list of answer lines into a single string and appends it to QnADict\n",
    "            tempDict['answer'] = ''.join(tempDict['answer'])\n",
    "            QnADict.append(tempDict)\n",
    "        # Init a new tempDict to hold the newly detected question\n",
    "        tempDict = {\"question\": entry[1:], \"answer\": []}\n",
    "    else:\n",
    "        #If it does not start with a #, meaning its an answer, append it to answer list\n",
    "        tempDict[\"answer\"].append(entry)\n",
    "\n",
    "# Append the last entry into QnADict to ensure all QnAs are included\n",
    "if tempDict:\n",
    "    tempDict['answer'] = ''.join(tempDict['answer'])\n",
    "    QnADict.append(tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66b89e87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question  1 :\n",
      "write a python function to add two user provided numbers and return the sum\n",
      "\n",
      "def add_two_numbers(num1, num2):\n",
      "    sum = num1 + num2\n",
      "    return sum\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question  2 :\n",
      "write a python program to add two numbers \n",
      "\n",
      "num1 = 2\n",
      "num2 = 3\n",
      "sum = num1 + num2\n",
      "print(f'Sum: {sum}')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question  3 :\n",
      "Create a function to calculate the sum of a sequence of integers.\n",
      "\n",
      "def sum_sequence(sequence):\n",
      "  sum = 0\n",
      "  for num in sequence:\n",
      "    sum += num\n",
      "  return sum\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question  4 :\n",
      "Generate a Python code for crawling a website for a specific type of data such as phone numbers.\n",
      "\n",
      "import requests\n",
      "import re\n",
      "\n",
      "def crawl_website_for_phone_numbers(website):\n",
      "    response = requests.get(website)\n",
      "    phone_numbers = re.findall('\\d{3}-\\d{3}-\\d{4}', response.text)\n",
      "    return phone_numbers\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    print(crawl_website_for_phone_numbers('www.example.com'))\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "Question  5 :\n",
      "Create a Python list comprehension to get the squared values of a list [1, 2, 3, 5, 8, 13].\n",
      "\n",
      "[x*x for x in [1, 2, 3, 5, 8, 13]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for tempDict in QnADict:\n",
    "    print(\"\\nQuestion \", i+1, \":\")\n",
    "    i+=1\n",
    "    print(tempDict['question'][1:])\n",
    "    print(tempDict['answer'])\n",
    "    if i>4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de10f59",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3f0de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize import tokenize, untokenize\n",
    "import io\n",
    "import keyword\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aef1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizerWithDataAugmentation(codeString, maskFactor=0.25):\n",
    "    \n",
    "    # dict for storing mapping of the original variable name to their masked versions\n",
    "    maskedVar = {}   \n",
    "    \n",
    "    # List some built in functions that should be ignored when masking and add them to the keyword list\n",
    "    ignoreList = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'zip', 'char', 'list', 'dict', 'tuple', 'set', \n",
    "                  'len', 'sum', 'min', 'max']\n",
    "    ignoreList.extend(keyword.kwlist)\n",
    "    \n",
    "    # A counter for generating unique name values\n",
    "    var_counter = 1\n",
    "    \n",
    "    # List of generated tokens together with its information\n",
    "    tokens = list(tokenize(io.BytesIO(codeString.encode('utf-8')).readline))\n",
    "    \n",
    "    # Initialize an empty list to store the final tokens\n",
    "    tokenizedOutput = []\n",
    "\n",
    "    # Loop through all the tokens\n",
    "    for token in tokens:\n",
    "        # Only grab the token type and token string\n",
    "        token_type, token_string, _, _, _ = token\n",
    "\n",
    "        # This part is to handle variable naming\n",
    "        # Checks if the token type == name and the string is not in the ignored list\n",
    "        if token_type == 1 and token_string not in ignoreList:\n",
    "            \n",
    "            # Case 1: If token is in a keyword, add them into ignore list and then append it directly to the output\n",
    "            if token_string in ['def', '.', 'import', 'raise', 'except', 'class']:\n",
    "                ignoreList.append(token_string)\n",
    "                tokenizedOutput.append((token_type, token_string))\n",
    "                \n",
    "            # Case 2: If token has already been masked, append the masked version instead\n",
    "            elif token_string in maskedVar:\n",
    "                tokenizedOutput.append((token_type, maskedVar[token_string]))\n",
    "                \n",
    "            # Case 3: If the random number is greater than 1-mask factor, mask the token name as var x \n",
    "            # (where x is the number in the counter). Then add 1 to the counter then appends it to the output\n",
    "            elif random.uniform(0, 1) > 1 - maskFactor:\n",
    "                maskedVar[token_string] = f'var{var_counter}'\n",
    "                var_counter += 1\n",
    "                tokenizedOutput.append((token_type, maskedVar[token_string]))\n",
    "            \n",
    "            # Case 4: Other cases, add the token to the ignore list and append the type and string to the output\n",
    "            else:    \n",
    "                ignoreList.append(token_string)\n",
    "                tokenizedOutput.append((token_type, token_string))\n",
    "        \n",
    "        # If the token type is not a name or found in the ignored list, append it directly to the output\n",
    "        else:\n",
    "            tokenizedOutput.append((token_type, token_string))\n",
    "            \n",
    "    return tokenizedOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe8733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(63, 'utf-8'), (1, 'def'), (1, 'var1'), (54, '('), (1, 'num1'), (54, ','), (1, 'num2'), (54, ')'), (54, ':'), (4, '\\n'), (5, '    '), (1, 'sum'), (54, '='), (1, 'num1'), (54, '+'), (1, 'num2'), (4, '\\n'), (1, 'return'), (1, 'sum'), (4, '\\n'), (62, '\\n'), (62, '\\n'), (6, ''), (0, '')]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizerWithDataAugmentation(QnADict[0]['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08615d46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def add_two_numbers (num1 ,num2 ):\n",
      "    sum =num1 +num2 \n",
      "    return sum \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(untokenize(tokenizerWithDataAugmentation(QnADict[0]['answer'])).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4997d7",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39f40fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68d1d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>write a python function to add two user provi...</td>\n",
       "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>write a python program to add two numbers \\n</td>\n",
       "      <td>num1 = 2\\nnum2 = 3\\nsum = num1 + num2\\nprint(f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Create a function to calculate the sum of a s...</td>\n",
       "      <td>def sum_sequence(sequence):\\n  sum = 0\\n  for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generate a Python code for crawling a website...</td>\n",
       "      <td>import requests\\nimport re\\n\\ndef crawl_websit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Create a Python list comprehension to get the...</td>\n",
       "      <td>[x*x for x in [1, 2, 3, 5, 8, 13]]\\n\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   write a python function to add two user provi...   \n",
       "1       write a python program to add two numbers \\n   \n",
       "2   Create a function to calculate the sum of a s...   \n",
       "3   Generate a Python code for crawling a website...   \n",
       "4   Create a Python list comprehension to get the...   \n",
       "\n",
       "                                              answer  \n",
       "0  def add_two_numbers(num1, num2):\\n    sum = nu...  \n",
       "1  num1 = 2\\nnum2 = 3\\nsum = num1 + num2\\nprint(f...  \n",
       "2  def sum_sequence(sequence):\\n  sum = 0\\n  for ...  \n",
       "3  import requests\\nimport re\\n\\ndef crawl_websit...  \n",
       "4           [x*x for x in [1, 2, 3, 5, 8, 13]]\\n\\n\\n  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythonQuestions_df = pd.DataFrame(QnADict)\n",
    "pythonQuestions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9f0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# deciding factor for split the data into 90% training and 10% validation\n",
    "trainOrValidationSplit = np.random.rand(len(pythonQuestions_df)) < 0.9\n",
    "train_df = pythonQuestions_df[trainOrValidationSplit]\n",
    "val_df = pythonQuestions_df[~trainOrValidationSplit]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04b983a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QnADict shape is: (2815, 2)\n",
      "train_df shape is: (2500, 2)\n",
      "val_df shape is: (315, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generate a REST API with Python and Flask tha...</td>\n",
       "      <td>from flask import Flask, request\\nfrom flask_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Python program to calculate the avera...</td>\n",
       "      <td>\\nlist_of_positive_integers = [1, 5, 6, 7, 8]\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Develop a Python function to predict the clas...</td>\n",
       "      <td>import pandas as pd\\ncsv_url = 'http://test.te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0   Generate a REST API with Python and Flask tha...   \n",
       "1   Write a Python program to calculate the avera...   \n",
       "2   Develop a Python function to predict the clas...   \n",
       "\n",
       "                                              answer  \n",
       "0  from flask import Flask, request\\nfrom flask_s...  \n",
       "1  \\nlist_of_positive_integers = [1, 5, 6, 7, 8]\\...  \n",
       "2  import pandas as pd\\ncsv_url = 'http://test.te...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"QnADict shape is: {pythonQuestions_df.shape}\")\n",
    "print(f\"train_df shape is: {train_df.shape}\")\n",
    "print(f\"val_df shape is: {val_df.shape}\")\n",
    "\n",
    "train_df.head(3)\n",
    "val_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d038665",
   "metadata": {},
   "source": [
    "### Vocabulary Construction - torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2a3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext.data import Field, BucketIterator, Iterator\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a53cd749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85efe1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed configuration for reproducability\n",
    "SEED = 200803\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5001109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading spacy for its tokenizing function\n",
    "spacyNLP = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Transform into lower case\n",
    "def spacyTokenizer(text):\n",
    "    return [token.text.lower() for token in spacyNLP(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60c189c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and Output object defining how they are processed.\n",
    "# set init token and eos token to empty meaning no special token will be added\n",
    "\n",
    "# Input field (natural language)\n",
    "Input = Field(tokenize = spacyTokenizer,\n",
    "              init_token='', \n",
    "              eos_token='', \n",
    "              lower=True)\n",
    "\n",
    "# Output field (code)\n",
    "Output = Field(tokenize = tokenizerWithDataAugmentation,\n",
    "               init_token='', \n",
    "               eos_token='', \n",
    "               lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591ba4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping each processing steps (fields) to its corresponding data\n",
    "fields = [('Input', Input),('Output', Output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a646ea06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Further data augmentation to increase vocab size\n",
    "# validation data will not be augmented, just the training data\n",
    "\n",
    "# Initiate list for training and validation examples\n",
    "trainExList = []   # Training example list\n",
    "valExList = []     # Validation example list\n",
    "\n",
    "# Parameter for augmentation (number of times to replicate training data)\n",
    "expandXfold = 500\n",
    "\n",
    "# For 500 iterations\n",
    "for j in range(expandXfold):\n",
    "    # For each rows in train_df\n",
    "    for i in range(train_df.shape[0]):\n",
    "        try:\n",
    "            # Create examples for the training data and append it to trainExList\n",
    "            trainEx = data.Example.fromlist([train_df.question[i], train_df.answer[i]], fields)\n",
    "            trainExList.append(trainEx)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "# For each rows in val_df\n",
    "for i in range(val_df.shape[0]):\n",
    "    try:\n",
    "        # Create examples for the validation data and append it to valExExList\n",
    "        valEx = data.Example.fromlist([val_df.question[i], val_df.answer[i]], fields)\n",
    "        valExList.append(valEx)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15332914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 1248500\n",
      "Total validation samples: 315\n"
     ]
    }
   ],
   "source": [
    "# Print out the samples\n",
    "print(\"Total training samples:\", len(trainExList))\n",
    "print(\"Total validation samples:\", len(valExList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526d6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "train_dataset = data.Dataset(trainExList, fields)\n",
    "validation_dataset =  data.Dataset(valExList, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "467b027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab building, min_freq is set to 0 such that all tokens are included regardless of frequency\n",
    "Input.build_vocab(train_dataset, min_freq = 0)\n",
    "Output.build_vocab(train_dataset, min_freq = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11e29f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pickle for serializing vocab objects\n",
    "import pickle\n",
    "\n",
    "# Serialize vocab and write them into the Vocab folder\n",
    "def saveVocabulary(vocab, path):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(vocab, output)\n",
    "    output.close()\n",
    "    \n",
    "saveVocabulary(Input.vocab, \"Vocab/codegenerator_input_vocab.pkl\")\n",
    "saveVocabulary(Output.vocab, \"Vocab/codegenerator_output_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bb53dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks if cuda is available, else use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07610221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(63, 'utf-8'),\n",
       " (1, 'def'),\n",
       " (1, 'var1'),\n",
       " (54, '('),\n",
       " (1, 'var2'),\n",
       " (54, ','),\n",
       " (1, 'var3'),\n",
       " (54, ')'),\n",
       " (54, ':'),\n",
       " (4, '\\n'),\n",
       " (5, '    '),\n",
       " (1, 'sum'),\n",
       " (54, '='),\n",
       " (1, 'var2'),\n",
       " (54, '+'),\n",
       " (1, 'var3'),\n",
       " (4, '\\n'),\n",
       " (1, 'return'),\n",
       " (1, 'sum'),\n",
       " (4, ''),\n",
       " (6, ''),\n",
       " (0, '')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dae7d",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "495a8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # Init class\n",
    "    def __init__(self, \n",
    "                 inputDim,                   # Input vocab size\n",
    "                 hidDim,                     # Hidden dimension (size of the vector representing each token)\n",
    "                 n_layers,                   # Number of layers (containing attention mechanism + feedforward)\n",
    "                 n_heads,                    # Number of attention heads\n",
    "                 posWiseFeedForwardDim,      # Dimension of the position wise feedforward network in each layer\n",
    "                 dropout,                    # Dropout rate (randomly setting activation to 0)\n",
    "                 device,\n",
    "                 maxLength = 1000):          # Max length of input sequence for positional encoding\n",
    "        super().__init__()\n",
    "        \n",
    "        # Device\n",
    "        self.device = device\n",
    "        \n",
    "        # Embed the token (which is currently in a form of integer indexes) into a dense vector of size hidDim\n",
    "        self.tokenEmbedding = nn.Embedding(inputDim, hidDim)\n",
    "        \n",
    "        # Positional Embedding: Embed the order of the tokens in the sequence, \n",
    "        # helping model to understand the language structure\n",
    "        self.positionalEmbedding = nn.Embedding(maxLength, hidDim)\n",
    "        \n",
    "        # List of encoder layers (containing multi headed attention and feed forward network)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(hidDim, \n",
    "                                                  n_heads, \n",
    "                                                  posWiseFeedForwardDim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        # Regularization with droupout preventing overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Scaling factor, help normalize input embedding, avoiding the embeddings from being too large/too small\n",
    "        # Scaling factor is square root of the Q or K dimension (hidDim)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidDim])).to(device)\n",
    "     \n",
    "    \n",
    "    \n",
    "    # Forward pass\n",
    "    # src is the input sequence\n",
    "    # srcMask is to prevent handling specific tokens such as padding tokens\n",
    "    def forward(self, src, srcMask):\n",
    "        \n",
    "        batchSize = src.shape[0]\n",
    "        srcLength = src.shape[1]\n",
    "        \n",
    "        # This will be [batchSize , srcLength]\n",
    "        # Create positional index for each token and expand it (add batch dimension), repeat for all sequence in the batch\n",
    "        pos = torch.arange(0, srcLength).unsqueeze(0).repeat(batchSize, 1).to(self.device)\n",
    "        \n",
    "        # Embedding and positional encoding\n",
    "        # Converts input token indices into dense vectors, normalize by scaling them, and adding position information\n",
    "        # Applies dropout to the result for regularization\n",
    "        src = self.dropout((self.tokenEmbedding(src) * self.scale) + self.positionalEmbedding(pos))\n",
    "        \n",
    "        \n",
    "        # Encoder Layer\n",
    "        # For each encoder layer,\n",
    "        for layer in self.layers:\n",
    "            # Applies self attention and feed forward\n",
    "            src = layer(src, srcMask)\n",
    "            \n",
    "        return src\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90443055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Layer\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidDim,                   # Hidden dimension (size of the vector representing each token)\n",
    "                 n_heads,                  # Number of attention heads\n",
    "                 posWiseFeedForwardDim,    # Dimension of the position wise feedforward network in each layer\n",
    "                 dropout,                  # Dropout rate (randomly setting activation to 0)\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer normalization after self attention to stabilize output\n",
    "        self.layerNormalizationForselfAttention = nn.LayerNorm(hidDim)\n",
    "        # Layer normalization after feed forward network to avoid output growing too large/small  \n",
    "        # after applying activation function\n",
    "        self.layerNormalizationForFeedForward = nn.LayerNorm(hidDim)\n",
    "        \n",
    "        \n",
    "        # Multi head attention. Dropout rate is introduced to regularize the model\n",
    "        self.multiHeadAttention = MultiHeadAttentionLayer(hidDim, n_heads, dropout, device)\n",
    "        \n",
    "        # Apply position wise feed forward network to each position of the sequence\n",
    "        self.positionwiseFeedForward = PositionwiseFeedforwardLayer(hidDim, \n",
    "                                                                    posWiseFeedForwardDim, \n",
    "                                                                    dropout)\n",
    "        \n",
    "        # Applies dropout to the output of the attention and feedforward layers to prevent overfitting\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, src, srcMask): \n",
    "                \n",
    "        # Self attention, returns a multihead self attention output (attentionOutput), and an ignored weight (_)\n",
    "        # srcMask is used to prevent attention to certain positions (e.g., padding tokens)\n",
    "        # src (input sequence) is used as query, key, and value\n",
    "        attentionOutput, _ = self.multiHeadAttention(src, src, src, srcMask)\n",
    "        \n",
    "        # Add input to the output of the self attention, preserving the original information\n",
    "        # Applies dropout to regularize model\n",
    "        # Normalize the combined output\n",
    "        src = self.layerNormalizationForselfAttention(src + self.dropout(attentionOutput))\n",
    "        \n",
    "        \n",
    "        # Positionwise feedforward with the output of the self attention layer before as input\n",
    "        attentionOutput = self.positionwiseFeedForward(src)\n",
    "        \n",
    "        # Add input to the output of the Positionwise feedforward network, again, to help preserve the original information\n",
    "        # Applies dropout to regularize model\n",
    "        # Normalize the combined output\n",
    "        src = self.layerNormalizationForFeedForward(src + self.dropout(attentionOutput))\n",
    "        \n",
    "        \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf43c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positionwise FeedforwardLayer\n",
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidDim, posWiseFeedForwardDim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # A fully connected layer mapping from hidDim to posWiseFeedForwardDim (transform input into higher dimension)\n",
    "        self.fullyConnectedLayer_1 = nn.Linear(hidDim, posWiseFeedForwardDim)\n",
    "        # A fully connected layer mapping from posWiseFeedForwardDim to hidDim (transform dimension back to original)\n",
    "        self.fullyConnectedLayer_2 = nn.Linear(posWiseFeedForwardDim, hidDim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    # Forward Pass\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Pass to first fully connected layer\n",
    "        # Applies ReLU activation function (keeps only positive values)\n",
    "        # Then, apply dropout to the result\n",
    "        x = self.dropout(torch.relu(self.fullyConnectedLayer_1(x)))\n",
    "        \n",
    "        # Pass to the second fully connected layer to transform it back to the original\n",
    "        x = self.fullyConnectedLayer_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c31a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multihead Attention Layer\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, hidDim, n_heads, dropout, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Ensure that the hidden dimension is divisible by the number of attention heads\n",
    "        assert hidDim % n_heads == 0\n",
    "        \n",
    "        \n",
    "        # Dimension storing\n",
    "        # Total dimension of the hidden states\n",
    "        self.hidDim = hidDim\n",
    "        # Total number of attention heads\n",
    "        self.n_heads = n_heads\n",
    "        # Size of each attention head\n",
    "        self.headDim = hidDim // n_heads\n",
    "        \n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        # Transform input sequences (query, key and value) into the same hidden dimension\n",
    "        self.fullyConnectedLayer_q = nn.Linear(hidDim, hidDim)\n",
    "        self.fullyConnectedLayer_k = nn.Linear(hidDim, hidDim)\n",
    "        self.fullyConnectedLayer_v = nn.Linear(hidDim, hidDim)\n",
    "        # Combine output of all the attention heads back to the original hidden dimension size\n",
    "        self.fullyConnectedLayer_o = nn.Linear(hidDim, hidDim)\n",
    "          \n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Scaling to avoid large values in softmax function\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.headDim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \n",
    "        batchSize = query.shape[0]\n",
    "        \n",
    "        # Transform the input to a space with the same hidden dimension   \n",
    "        Q = self.fullyConnectedLayer_q(query)\n",
    "        K = self.fullyConnectedLayer_k(key)\n",
    "        V = self.fullyConnectedLayer_v(value)\n",
    "        \n",
    "        \n",
    "        # Reshape Q, K, and V to split the hidden dimension into multiple heads\n",
    "        # Each head process a portion of the dimension headDim\n",
    "        # Rearrange dimension to separate the heads as a separate dimension to ease attention computation of each head\n",
    "        # Shape is transformed from [batchSize, srclength, n_heads, hidDim] \n",
    "        # into [batch size, n_heads, srclength, headDim] for dot product\n",
    "        Q = Q.view(batchSize, -1, self.n_heads, self.headDim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batchSize, -1, self.n_heads, self.headDim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batchSize, -1, self.n_heads, self.headDim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        \n",
    "        # Compute dot product of Q and K for attention score\n",
    "        # Scaled to avoid excessively large values\n",
    "        focus = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        \n",
    "        # Apply mask to prevent attention to certain tokens (ex: padding tokens)\n",
    "        # Masked positions are set to very large negative number such that when softmax is applied, it becomes 0\n",
    "        if mask is not None:\n",
    "            focus = focus.masked_fill(mask == 0, -1e10)\n",
    "\n",
    "        \n",
    "        # Apply softmax to get the attention weight\n",
    "        attention = torch.softmax(focus, dim = -1)\n",
    "\n",
    "        \n",
    "        # Apply dropout on attention weight, then calculate weighted sum of the values\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "\n",
    "        \n",
    "        # Permute the dimension\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        # Combine the output from all attention into a single dimension (hidDim)\n",
    "        x = x.view(batchSize, -1, self.hidDim)\n",
    "\n",
    "        \n",
    "        # Apply linear transformation to combine the output back to the hidDim size\n",
    "        x = self.fullyConnectedLayer_o(x)\n",
    "\n",
    "        \n",
    "        return x, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225bab1",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "872c24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 outputDim,                 # Output vocab size\n",
    "                 hidDim,                    # Hidden dimension (size of the vector representing each token)\n",
    "                 n_layers,                  # Number of layers\n",
    "                 n_heads,                   # Number of attention heads\n",
    "                 posWiseFeedForwardDim,     # Dimension of the position wise feedforward network in each layer\n",
    "                 dropout,                   # Dropout rate (randomly setting activation to 0)\n",
    "                 device,\n",
    "                 maxLength = 10000):        # Max length of sequence for the decoder to handle\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Embed the token (which is currently in a form of integer indexes) into a dense vector of size hidDim\n",
    "        self.tokenEmbedding = nn.Embedding(outputDim, hidDim)\n",
    "        # Embed the order of the tokens in the sequence, helping model to understand the language structure\n",
    "        self.positionalEmbedding = nn.Embedding(maxLength, hidDim)\n",
    "        \n",
    "        # List of n_layers amount of decoder layers\n",
    "        self.layers = nn.ModuleList([DecoderLayer(hidDim, \n",
    "                                                  n_heads, \n",
    "                                                  posWiseFeedForwardDim, \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        # A fully connected layer transforming hidDim back into output vocab dimension\n",
    "        # This is used to predict the next token in the sequence\n",
    "        self.fullyConnectedLayer_out = nn.Linear(hidDim, outputDim)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Scaling factor, help normalize the embedding, avoiding from it being too large/too small\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hidDim])).to(device)\n",
    "        \n",
    "        \n",
    "    # Forward pass\n",
    "    # trg is the input sequence for the decoder\n",
    "    # encoderSrc is the encoder's output\n",
    "    # trgMask and srcMask are both to prevent handling specific tokens such as padding tokens    \n",
    "    def forward(self, trg, encoderSrc, trgMask, srcMask):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #encoderSrc = [batch size, src len, hid dim]\n",
    "        #trgMask = [batch size, 1, trg len, trg len]\n",
    "        #srcMask = [batch size, 1, 1, src len]\n",
    "        \n",
    "        batchSize = trg.shape[0]\n",
    "        trgLength = trg.shape[1]\n",
    "        \n",
    "        # Positional encoding\n",
    "        # Create positional index for each token and expand it to match the batch size\n",
    "        pos = torch.arange(0, trgLength).unsqueeze(0).repeat(batchSize, 1).to(self.device)\n",
    "        \n",
    "        # Converts input token indices into dense vectors, normalize by scaling them, and adding position information\n",
    "        # Applies dropout to the result\n",
    "        trg = self.dropout((self.tokenEmbedding(trg) * self.scale) + self.positionalEmbedding(pos))\n",
    "        \n",
    "        \n",
    "        # For each decoder layer,(Multi headed attention and Feed forward)\n",
    "        for layer in self.layers:\n",
    "            # Returns updated target sequence and attention weight \n",
    "            # representing how much each token in the target sequence attends to tokens in the source sequence\n",
    "            trg, attention = layer(trg, encoderSrc, trgMask, srcMask)\n",
    "\n",
    "        \n",
    "        # Linear classification \n",
    "        output = self.fullyConnectedLayer_out(trg)\n",
    "\n",
    "        # Returns output and attention weight\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b7df25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hidDim,                    # Hidden dimension (size of the vector representing each token)\n",
    "                 n_heads,                   # Number of attention heads\n",
    "                 posWiseFeedForwardDim,     # Dimension of the position wise feedforward network in each layer\n",
    "                 dropout,                   # Dropout rate (randomly setting activation to 0)\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Layer normalization after self attention to stabilize output\n",
    "        self.layerNormalizationForselfAttention = nn.LayerNorm(hidDim)\n",
    "        \n",
    "        # Layer normalization after attention mechanism involving encoder's output.\n",
    "        self.layerNormalizationForEncOutputselfAttention = nn.LayerNorm(hidDim)\n",
    "        \n",
    "        # Layer normalization after feed forward network to avoid output growing too large/small  \n",
    "        # after applying activation function\n",
    "        self.layerNormalizationForFeedForward = nn.LayerNorm(hidDim)\n",
    "        \n",
    "        \n",
    "        # Multi head attention. Dropout rate is introduced to regularize the model\n",
    "        self.multiHeadAttention = MultiHeadAttentionLayer(hidDim, n_heads, dropout, device)\n",
    "        \n",
    "        # Multi head attention focusing on encoder's output when generating sequence. \n",
    "        # Dropout rate is introduced to regularize the model\n",
    "        self.encodermultiHeadAttention = MultiHeadAttentionLayer(hidDim, n_heads, dropout, device)\n",
    "        \n",
    "        # Apply position wise feed forward network to each position in the input sequence\n",
    "        self.positionwiseFeedForward = PositionwiseFeedforwardLayer(hidDim, \n",
    "                                                                     posWiseFeedForwardDim, \n",
    "                                                                     dropout)\n",
    "        \n",
    "        # Applies dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Forward Pass\n",
    "    def forward(self, trg,  encoderSrc, trgMask, srcMask):\n",
    "\n",
    "        # Self-attention within the target sequence\n",
    "        # trg is used as query, key, and value\n",
    "        # trgMask prevents attention to certain positions (like future tokens)\n",
    "        attentionOutput, _ = self.multiHeadAttention(trg, trg, trg, trgMask)\n",
    "        \n",
    "        \n",
    "        # Add input to the output of the self-attention, help preserving the original information\n",
    "        # Applies dropout to regularize the model\n",
    "        # Normalize the combined output\n",
    "        trg = self.layerNormalizationForselfAttention(trg + self.dropout(attentionOutput))\n",
    "\n",
    "            \n",
    "        # Attention to allow the decoder focusing on the encoder's output\n",
    "        # encoderSrc is used for key and value while trg is used for query\n",
    "        attentionOutput, attention = self.encodermultiHeadAttention(trg,  encoderSrc,  encoderSrc, srcMask)\n",
    "        \n",
    "        # Add input to the output of the encoder output focused attention, help preserving the original information\n",
    "        # Applies dropout to regularize model\n",
    "        # Normalize the combined output\n",
    "        trg = self.layerNormalizationForEncOutputselfAttention(trg + self.dropout(attentionOutput))\n",
    "        \n",
    "        # Positionwise feedforward with the output encoder focused output attention layer before as input\n",
    "        attentionOutput = self.positionwiseFeedForward(trg)\n",
    "        \n",
    "        # Add input to the output of the positionwise feedforward network, again, to help preserve the original information\n",
    "        # Applies dropout to regularize the model\n",
    "        # Normalize the combined output\n",
    "        trg = self.layerNormalizationForFeedForward(trg + self.dropout(attentionOutput))\n",
    "        \n",
    "        \n",
    "        return trg, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff9c046",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28a24f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequence2SequenceModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder,             # Encoder for the model\n",
    "                 decoder,             # Decoder for the model\n",
    "                 srcPaddingIndex,     # Padding index for the source sequence\n",
    "                 trgPaddingIndex,     # Padding index for the target sequence\n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.srcPaddingIndex = srcPaddingIndex\n",
    "        self.trgPaddingIndex = trgPaddingIndex\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    # Create mask to ignore padding tokens in source\n",
    "    def createSrcMask(self, src):\n",
    "        # Returns true if it is not a padding token, and false otherwise\n",
    "        # Add dimension to align shape with the shape of the attention mechanism\n",
    "        # unsqueeze 1 is for attention heads, and unsqueeze 2 is for target sequence\n",
    "        srcMask = (src != self.srcPaddingIndex).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        return srcMask\n",
    "    \n",
    "    \n",
    "    # Create mask to ignore padding tokens in target\n",
    "    def createTrgMask(self, trg):\n",
    "        # Returns true if it is not a padding token, and false otherwise\n",
    "        # Add dimension to align shape with the shape of the attention mechanism\n",
    "        # unsqueeze 1 is for attention heads, and unsqueeze 2 is for target sequence\n",
    "        trgPaddingMask = (trg != self.trgPaddingIndex).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        trgLength = trg.shape[1]\n",
    "        \n",
    "        # Look ahead mask to make sure that the model focus on the current and previous position, not future positions\n",
    "        # Creates a lower triangular matrix and convert the content into boolean values\n",
    "        # Triangular matrix is used since it ensure that each token can only \"focus\" on itself and the tokens before it\n",
    "        # Simulating real predictions\n",
    "        lookaheadMask = torch.tril(torch.ones((trgLength, trgLength), device = self.device)).bool()\n",
    "        \n",
    "        # Combine both masks to produce target mask\n",
    "        trgMask = trgPaddingMask & lookaheadMask\n",
    "        \n",
    "        return trgMask\n",
    "    \n",
    "    \n",
    "    # Feed forward\n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        # Creates the mask for both src and trg\n",
    "        srcMask = self.createSrcMask(src)\n",
    "        trgMask = self.createTrgMask(trg)\n",
    "        \n",
    "        # Pass input into the sequence\n",
    "        encoderSrc = self.encoder(src, srcMask)\n",
    "        # Pass target and output of the encoder into decoder        \n",
    "        output, attention = self.decoder(trg, encoderSrc, trgMask, srcMask)\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4853f",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4202d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "InputDimension = len(Input.vocab)\n",
    "OutputDimension = len(Output.vocab)\n",
    "\n",
    "# Hidden dimension\n",
    "HiddenDimension = 256\n",
    "\n",
    "# n_layers\n",
    "EncLayers = 3\n",
    "DecLayers = 3\n",
    "\n",
    "# n_heads\n",
    "EncHeads = 16\n",
    "DecHeads = 16\n",
    "\n",
    "# posWiseFeedForwardDim\n",
    "EncPositionWiseFeedForwardDimension = 512\n",
    "DecPositionWiseFeedForwardDimension = 512\n",
    "\n",
    "# Dropout\n",
    "EncDropout = 0.1\n",
    "DecDropout = 0.1\n",
    "\n",
    "# Initialize encoder with the set attributes\n",
    "enc = Encoder(InputDimension,\n",
    "              HiddenDimension,\n",
    "              EncLayers,\n",
    "              EncHeads,\n",
    "              EncPositionWiseFeedForwardDimension,\n",
    "              EncDropout,\n",
    "              device)\n",
    "\n",
    "# Initialize decoder with the set attributes\n",
    "dec = Decoder(OutputDimension,\n",
    "              HiddenDimension,\n",
    "              DecLayers,\n",
    "              DecHeads,\n",
    "              DecPositionWiseFeedForwardDimension,\n",
    "              DecDropout,\n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afbef23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store numerical index of the padding token\n",
    "srcPaddingIndexInput = Input.vocab.stoi[Input.pad_token]\n",
    "trgPaddingIndexInput = Output.vocab.stoi[Output.pad_token]\n",
    "\n",
    "# Initialize the encoder-decoder model\n",
    "model = Sequence2SequenceModel(enc, dec, srcPaddingIndexInput, trgPaddingIndexInput, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51f9bdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 9,789,288 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc5e813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init weights in order to avoid weight values that are too large/small\n",
    "def initWeights(module):\n",
    "    weight = getattr(module, 'weight', None)\n",
    "    # checks if module has weights and if the dimension > 1\n",
    "    if weight is not None and weight.dim() > 1:\n",
    "        # Glorot (Xavier) init was choosen since it is often used for general purpose init\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "\n",
    "# Apply weight\n",
    "model.apply(initWeights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57728416",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b83f0",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a86e2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Cross Entropy Loss accomodating distributions, label smoothening, and accepting raw logits\n",
    "class CrossEntropyLoss(nn.CrossEntropyLoss):\n",
    "\n",
    "    def __init__(self, \n",
    "                 weight=None,               # Weight\n",
    "                 ignore_index=-100,         # Ignore index\n",
    "                 reduction='mean',          # Loss reduction, currently set to average\n",
    "                 smooth_eps=None,           # Smoothing epsilon\n",
    "                 smooth_dist=None,          # Smoothing distribution\n",
    "                 areLogits=True):           # Boolean for raw logits/ log probabilities\n",
    "        super(CrossEntropyLoss, self).__init__(weight=weight,\n",
    "                                               ignore_index=ignore_index, \n",
    "                                               reduction=reduction)\n",
    "        \n",
    "        # Smooth epsilon\n",
    "        self.smooth_eps = smooth_eps\n",
    "        \n",
    "        # Smooth distributions\n",
    "        self.smooth_dist = smooth_dist\n",
    "        \n",
    "        # Logits\n",
    "        self.areLogits = areLogits\n",
    "    \n",
    "    \n",
    "    def forward(self, input, target, smooth_dist=None):\n",
    "        # If distribution is not provided\n",
    "        if smooth_dist is None:\n",
    "            # Use self attribute\n",
    "            smooth_dist = self.smooth_dist\n",
    "            \n",
    "        # Custom cross entropy function, returns the loss amount \n",
    "        return crossEntropy(input, \n",
    "                             target, \n",
    "                             weight=self.weight, \n",
    "                             ignore_index=self.ignore_index,\n",
    "                             reduction=self.reduction, \n",
    "                             smooth_eps=self.smooth_eps,\n",
    "                             smooth_dist=smooth_dist, \n",
    "                             areLogits=self.areLogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8bad744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(inputs,               # Inputs\n",
    "                  target,               # Ground truth\n",
    "                  weight=None,          # Weight\n",
    "                  ignore_index=-100,    # Ignore specific tokens\n",
    "                  reduction='mean',     # Reduce loss\n",
    "                  smooth_eps=None,      # Smoothing Epsilon \n",
    "                  smooth_dist=None,     # Smoothing distribution\n",
    "                  areLogits=True):      # Boolean for raw logits/ log probabilities\n",
    "    \n",
    "    # Sets smooth epsilon to 0 if not provided\n",
    "    if smooth_eps:\n",
    "        smooth_eps = smooth_eps\n",
    "    else:\n",
    "        smooth_eps = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOGITS OR PROBABILITY\n",
    "    # If target is a class index and no smoothening is applied\n",
    "    if isLongTensor(target) and smooth_eps == 0:\n",
    "        # If inputs are raw logits\n",
    "        if areLogits:\n",
    "            # Use cross entropy loss\n",
    "            return F.cross_entropy(inputs, \n",
    "                                   target, \n",
    "                                   weight, \n",
    "                                   ignore_index=ignore_index, \n",
    "                                   reduction=reduction)\n",
    "        # If inputs are probability\n",
    "        else:\n",
    "            # Use negative loss likelihood loss\n",
    "            return F.nll_loss(inputs, \n",
    "                              target, \n",
    "                              weight, \n",
    "                              ignore_index=ignore_index, \n",
    "                              reduction=reduction)\n",
    "        \n",
    "    \n",
    "    # LOG SOFTMAX\n",
    "    # If inputs are raw logits\n",
    "    if areLogits:\n",
    "        # Applies softmax to convert it into probability\n",
    "        # Then take the log of the probability\n",
    "        logSoftMax = F.log_softmax(inputs, dim=-1)\n",
    "    # If inputs are already log-probability\n",
    "    else:\n",
    "        logSoftMax = inputs\n",
    "    \n",
    "    \n",
    "        \n",
    "    # IGNORE MASK \n",
    "    # Init mask for ignored index for the loss  \n",
    "    ignoreIndexMask = None\n",
    "    # Number of classes from the inner most dimension of the input\n",
    "    n_classes = inputs.size(-1)\n",
    "\n",
    "    # If target is a class index and ignore index is >0\n",
    "    if isLongTensor(target) and ignore_index >= 0:\n",
    "        # Create boolean tensor where each element is true, false otherwise\n",
    "        ignoreIndexMask = target.eq(ignore_index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LABEL SMOOTHENING\n",
    "    # If smooth epsilon > 0 and smooth distribution is provided\n",
    "    if smooth_eps > 0 and smooth_dist is not None:\n",
    "        # If target is a class index\n",
    "        if isLongTensor(target):\n",
    "            # one hot encoding (add number of classes) into binary vector, ensure type is the same as input\n",
    "            target = oneHotEncoding(target, n_classes).type_as(inputs)\n",
    "        # If smooth_dist dimension < target dimension    \n",
    "        if smooth_dist.dim() < target.dim():\n",
    "            #  Add dimension to smooth dist to make sure it can adjust to match the target dimension\n",
    "            smooth_dist = smooth_dist.unsqueeze(0)\n",
    "        # Linear interpolation, blends target with smooth dist using smooth epsilon\n",
    "        target.lerp_(smooth_dist, smooth_eps)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # WEIGHTED LOGARITHMIC SOFTMAX\n",
    "    # If weight is provided (to apply different importance to different class)\n",
    "    if weight is not None:\n",
    "        # Add dimension to the weight to accomodate  logSoftMax shape on the first dimension\n",
    "        # Multiplies logSoftMax with class weight\n",
    "        logSoftMax = logSoftMax * weight.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOSS COMPUTATION\n",
    "    # If target is a class index\n",
    "    if isLongTensor(target):\n",
    "        # Smoothening amount = smoothening epsilon / number of classes\n",
    "        eps_sum = smooth_eps / n_classes\n",
    "        # Negative log likelihood\n",
    "        eps_nll = 1. - eps_sum - smooth_eps\n",
    "        # Extract log probability of the target class from logSoftMax\n",
    "        likelihood = logSoftMax.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
    "        # Weighted negative log likelihood of true class (eps_nll * likelihood)\n",
    "        # Then compute the contribution of label smoothening\n",
    "        # Finally, set to negative to get loss\n",
    "        loss = -(eps_nll * likelihood + eps_sum * logSoftMax.sum(-1))\n",
    "    else:\n",
    "        loss = -(target * logSoftMax).sum(-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # If ignoreIndexMask is provided\n",
    "    if ignoreIndexMask is not None:\n",
    "        # Ignore specific value\n",
    "        loss.masked_fill_(ignoreIndexMask, 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # REDUCTION SET\n",
    "    # If reduction is set to sum\n",
    "    if reduction == 'sum':\n",
    "        # Loss will be sum of all loss values\n",
    "        loss = loss.sum()\n",
    "    # If reduction is set to mean\n",
    "    elif reduction == 'mean':\n",
    "        # If no index ignored\n",
    "        if ignoreIndexMask is None:\n",
    "            # Simply calculate mean of all loss\n",
    "            loss = loss.mean()\n",
    "        # If present\n",
    "        else:\n",
    "            # loss will be the sum of all loss / Number of unignored elements\n",
    "            loss = loss.sum() / float(loss.size(0) - ignoreIndexMask.sum())\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d86795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding (represent categorical data as binary vector)\n",
    "def oneHotEncoding(categoryIndex, n_possibleCategories=None, ignore_index=None):\n",
    "\n",
    "    # If number of possible categories not provided, \n",
    "    if n_possibleCategories is None:\n",
    "        # Maximum category index set to the maximum value in category index + 1\n",
    "        n_possibleCategories = categoryIndex.max() + 1\n",
    "        \n",
    "    # Index size list to determine output shape\n",
    "    indexSize = list(categoryIndex.size())\n",
    "    \n",
    "    # Create new output tensor, set to uint8,\n",
    "    # Unpack and resize indexSize to add n_possibleCategories\n",
    "    # Init them with 0s\n",
    "    output = categoryIndex.new().byte().resize_(*indexSize, n_possibleCategories).zero_()\n",
    "    \n",
    "    # Set specific position (innermost dimension) of the output to 1 based on category index\n",
    "    output.scatter_(-1, categoryIndex.unsqueeze(-1), 1)\n",
    "    \n",
    "    # If ignore index is not none and negative\n",
    "    if ignore_index is not None and ignore_index >= 0:\n",
    "        # Boolean mask, returns true if category index == ignore_index, vice versa\n",
    "        # Replace with 0 where the output is true\n",
    "        output.masked_fill_(categoryIndex.eq(ignore_index).unsqueeze(-1), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53d71998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it is a long tensor to determine if it is a class index\n",
    "def isLongTensor(target):\n",
    "    # If it target has attribute data\n",
    "    if hasattr(target, 'data'):\n",
    "        target = target.data\n",
    "    \n",
    "    # Return true if its either CPU tensor or GPU tensor, else return false\n",
    "    return isinstance(target, torch.LongTensor) or isinstance(target, torch.cuda.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f266e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedNegativeLogLikelihoodLoss(inputPrediction, target, mask):\n",
    "    n_validTotal = mask.sum()\n",
    "    \n",
    "    # Init CrossEntropyLoss class\n",
    "    crossEntropy = CrossEntropyLoss(ignore_index = trgPaddingIndexInput, smooth_eps=0.15)\n",
    "    # Cross entropy loss computation with inputPrediction and target\n",
    "    loss = crossEntropy(inputPrediction, target)\n",
    "    loss = loss.to(device)\n",
    "    # Return loss and the number of valid elements (converted into int)\n",
    "    return loss, n_validTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0bbf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = maskedNegativeLogLikelihoodLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc7121",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e17745c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Target mask to handle certain tokens and prevent future tokens\n",
    "def createTrgMask(trg):\n",
    "    \n",
    "    # Boolean padding mask where padding tokens are set to false, otherwise true\n",
    "    # Added dimension to allow broadcasting into attention mechanism\n",
    "    trgPaddingMask = (trg != trgPaddingIndexInput).unsqueeze(1).unsqueeze(2)\n",
    "    \n",
    "    # Target length\n",
    "    trgLength = trg.shape[1]\n",
    "    \n",
    "    # Look ahead mask to make sure that the model focus on the current and previous position, not future positions\n",
    "    # Creates a lower triangular matrix and convert the content into boolean values\n",
    "    # Triangular matrix is used since it ensure that each token can only \"focus\" on itself and the tokens before it\n",
    "    # Simulating real predictions\n",
    "    lookaheadMask = torch.tril(torch.ones((trgLength, trgLength), device = device)).bool()\n",
    "    \n",
    "    # Combine mask into target mask\n",
    "    trgMask = trgPaddingMask & lookaheadMask\n",
    "\n",
    "    return trgMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78461522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    # Set to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Number of tokens processed\n",
    "    processedTokens = 0\n",
    "    # Loss values\n",
    "    totalLoss = []\n",
    "    \n",
    "    # For each batch (use tqdm for progress bar)\n",
    "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "        \n",
    "        loss = 0\n",
    "        \n",
    "        # Rearrange source and target to match model input shape: (sequence length, batch size)\n",
    "        src = batch.Input.permute(1, 0)\n",
    "        trg = batch.Output.permute(1, 0)\n",
    "        \n",
    "        # Target Mask\n",
    "        trgMask = createTrgMask(trg)\n",
    "        \n",
    "        # Reset optimizer gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, target shifted to predicts next token\n",
    "        output, _ = model(src, trg[:, :-1])  \n",
    "        \n",
    "        # Get output dimension\n",
    "        outputDim = output.shape[-1]\n",
    "        # Reshape into [batch size * trg len - 1, output dim]\n",
    "        output = output.contiguous().view(-1, outputDim)\n",
    "        # Reshape into [batch size * trg len - 1]\n",
    "        trg = trg[:, 1:].contiguous().view(-1)  \n",
    "        \n",
    "        # Loss computation\n",
    "        loss, n_validTotal = criterion(output, trg, trgMask)\n",
    "        \n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to avoid gradient getting too big\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # Optimization step\n",
    "        optimizer.step()\n",
    "        \n",
    "        totalLoss.append(loss.item() * n_validTotal)\n",
    "        processedTokens += n_validTotal\n",
    "        \n",
    "    return sum(totalLoss) / processedTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95875da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    processedTokens = 0\n",
    "    totalLoss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # For each batch (use tqdm for progress bar)\n",
    "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
    "            \n",
    "            # Rearrange source and target to match model input shape: (sequence length, batch size)\n",
    "            src = batch.Input.permute(1, 0)\n",
    "            trg = batch.Output.permute(1, 0)\n",
    "            \n",
    "            # Target Mask\n",
    "            trgMask = createTrgMask(trg)\n",
    "            \n",
    "            # Forward pass, target shifted to predicts next token\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            # Get output dimension\n",
    "            outputDim = output.shape[-1]\n",
    "            # Reshape into [batch size * trg len - 1, output dim]\n",
    "            output = output.contiguous().view(-1, outputDim)\n",
    "            # Reshape into [batch size * trg len - 1]\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            # Loss computation\n",
    "            loss, n_validTotal = criterion(output, trg, trgMask)\n",
    "            \n",
    "            totalLoss.append(loss.item() * n_validTotal)\n",
    "            processedTokens += n_validTotal\n",
    "\n",
    "    return sum(totalLoss) / processedTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06e9d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochTime(startTime, endTime):\n",
    "    elapsedTime = endTime - startTime\n",
    "    elapsedMins = int(elapsedTime / 60)\n",
    "    elapsedSecs = int(elapsedTime - (elapsedMins * 60))\n",
    "\n",
    "    return elapsedMins, elapsedSecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ca18b9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 37.55it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 81.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 11s\n",
      "\tTraining Loss: 4.943 | Training perplexity:  140.22\n",
      "\t Validation Loss: 4.272 |  Validation perplexity:   71.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.50it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 88.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 11s\n",
      "\tTraining Loss: 3.971 | Training perplexity:   53.01\n",
      "\t Validation Loss: 4.026 |  Validation perplexity:   56.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.28it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 11s\n",
      "\tTraining Loss: 3.727 | Training perplexity:   41.55\n",
      "\t Validation Loss: 3.924 |  Validation perplexity:   50.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.42it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 11s\n",
      "\tTraining Loss: 3.566 | Training perplexity:   35.36\n",
      "\t Validation Loss: 3.829 |  Validation perplexity:   46.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.67it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 81.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 11s\n",
      "\tTraining Loss: 3.438 | Training perplexity:   31.13\n",
      "\t Validation Loss: 3.784 |  Validation perplexity:   43.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.44it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 11s\n",
      "\tTraining Loss: 3.320 | Training perplexity:   27.67\n",
      "\t Validation Loss: 3.769 |  Validation perplexity:   43.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.51it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 11s\n",
      "\tTraining Loss: 3.224 | Training perplexity:   25.13\n",
      "\t Validation Loss: 3.705 |  Validation perplexity:   40.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 37.41it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 14s\n",
      "\tTraining Loss: 3.145 | Training perplexity:   23.22\n",
      "\t Validation Loss: 3.674 |  Validation perplexity:   39.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.11it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 11s\n",
      "\tTraining Loss: 3.052 | Training perplexity:   21.16\n",
      "\t Validation Loss: 3.677 |  Validation perplexity:   39.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.99it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 86.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 11s\n",
      "\tTraining Loss: 2.987 | Training perplexity:   19.82\n",
      "\t Validation Loss: 3.668 |  Validation perplexity:   39.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.36it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 11s\n",
      "\tTraining Loss: 2.921 | Training perplexity:   18.55\n",
      "\t Validation Loss: 3.611 |  Validation perplexity:   37.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.39it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 11s\n",
      "\tTraining Loss: 2.865 | Training perplexity:   17.55\n",
      "\t Validation Loss: 3.581 |  Validation perplexity:   35.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.81it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 11s\n",
      "\tTraining Loss: 2.819 | Training perplexity:   16.77\n",
      "\t Validation Loss: 3.585 |  Validation perplexity:   36.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 41.03it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 11s\n",
      "\tTraining Loss: 2.762 | Training perplexity:   15.84\n",
      "\t Validation Loss: 3.551 |  Validation perplexity:   34.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.94it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 11s\n",
      "\tTraining Loss: 2.724 | Training perplexity:   15.24\n",
      "\t Validation Loss: 3.596 |  Validation perplexity:   36.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.12it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 11s\n",
      "\tTraining Loss: 2.671 | Training perplexity:   14.45\n",
      "\t Validation Loss: 3.571 |  Validation perplexity:   35.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.92it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 0m 11s\n",
      "\tTraining Loss: 2.632 | Training perplexity:   13.91\n",
      "\t Validation Loss: 3.538 |  Validation perplexity:   34.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.85it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 0m 11s\n",
      "\tTraining Loss: 2.605 | Training perplexity:   13.53\n",
      "\t Validation Loss: 3.546 |  Validation perplexity:   34.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.35it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 0m 11s\n",
      "\tTraining Loss: 2.575 | Training perplexity:   13.13\n",
      "\t Validation Loss: 3.565 |  Validation perplexity:   35.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.99it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 0m 11s\n",
      "\tTraining Loss: 2.544 | Training perplexity:   12.73\n",
      "\t Validation Loss: 3.567 |  Validation perplexity:   35.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 39.04it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 88.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Time: 0m 11s\n",
      "\tTraining Loss: 2.516 | Training perplexity:   12.37\n",
      "\t Validation Loss: 3.576 |  Validation perplexity:   35.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.48it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Time: 0m 11s\n",
      "\tTraining Loss: 2.488 | Training perplexity:   12.04\n",
      "\t Validation Loss: 3.513 |  Validation perplexity:   33.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.20it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 91.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Time: 0m 11s\n",
      "\tTraining Loss: 2.476 | Training perplexity:   11.89\n",
      "\t Validation Loss: 3.563 |  Validation perplexity:   35.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.94it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 86.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Time: 0m 11s\n",
      "\tTraining Loss: 2.464 | Training perplexity:   11.75\n",
      "\t Validation Loss: 3.503 |  Validation perplexity:   33.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 37.53it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Time: 0m 11s\n",
      "\tTraining Loss: 2.448 | Training perplexity:   11.57\n",
      "\t Validation Loss: 3.528 |  Validation perplexity:   34.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.07it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Time: 0m 11s\n",
      "\tTraining Loss: 2.408 | Training perplexity:   11.12\n",
      "\t Validation Loss: 3.572 |  Validation perplexity:   35.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 40.31it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 90.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Time: 0m 11s\n",
      "\tTraining Loss: 2.412 | Training perplexity:   11.15\n",
      "\t Validation Loss: 3.520 |  Validation perplexity:   33.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 39.78it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 85.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Time: 0m 11s\n",
      "\tTraining Loss: 2.394 | Training perplexity:   10.95\n",
      "\t Validation Loss: 3.603 |  Validation perplexity:   36.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 39.15it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Time: 0m 11s\n",
      "\tTraining Loss: 2.363 | Training perplexity:   10.62\n",
      "\t Validation Loss: 3.565 |  Validation perplexity:   35.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:04<00:00, 38.41it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 89.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Time: 0m 11s\n",
      "\tTraining Loss: 2.359 | Training perplexity:   10.58\n",
      "\t Validation Loss: 3.562 |  Validation perplexity:   35.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 30\n",
    "# Gradient clipping value\n",
    "clip = 1\n",
    "# Save best validation loss\n",
    "bestValidationLoss = float('inf')\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Set start time\n",
    "    startTime = time.time()\n",
    "    \n",
    "    # Training and Validation data\n",
    "    trainExList = []\n",
    "    valExList = []\n",
    "    \n",
    "    \n",
    "    # For each rows in train_df\n",
    "    for i in range(train_df.shape[0]):\n",
    "        try:\n",
    "            # Create examples for the training data and append it to trainExList\n",
    "            trainEx = data.Example.fromlist([train_df.question[i], train_df.answer[i]], fields)\n",
    "            trainExList.append(trainEx)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # For each rows in val_df\n",
    "    for i in range(val_df.shape[0]):\n",
    "        try:\n",
    "            # Create examples for the validation data and append it to valExExList\n",
    "            valEx = data.Example.fromlist([val_df.question[i], val_df.answer[i]], fields)\n",
    "            valExList.append(valEx)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "      \n",
    "    \n",
    "    # Dataset creation\n",
    "    trainingDataset = data.Dataset(trainExList, fields)\n",
    "    validationDataset =  data.Dataset(valExList, fields)\n",
    "    \n",
    "    # Set batch size\n",
    "    batchSize = 16\n",
    "    \n",
    "    # Bucket iterator\n",
    "    trainingIterator, validationIterator = BucketIterator.splits((trainingDataset, validationDataset), \n",
    "                                                                 batch_size = batchSize, \n",
    "                                                                 sort_key = lambda x: len(x.Input),\n",
    "                                                                 sort_within_batch=True, \n",
    "                                                                 device = device)\n",
    "    \n",
    "    # Set training loss and validation loss\n",
    "    trainingLoss = train(model, trainingIterator, optimizer, criterion, clip)\n",
    "    validationLoss = evaluate(model, validationIterator, criterion)\n",
    "    \n",
    "    endTime = time.time()\n",
    "    \n",
    "    mins, secs = epochTime(startTime, endTime)\n",
    "    \n",
    "    if validationLoss < bestValidationLoss:\n",
    "        bestValidationLoss = validationLoss\n",
    "        torch.save(model.state_dict(), 'Model/FYPSeq2SeqModel.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {mins}m {secs}s')\n",
    "    print(f'\\tTraining Loss: {trainingLoss:.3f} | Training perplexity: {math.exp(trainingLoss):7.2f}')\n",
    "    print(f'\\t Validation Loss: {validationLoss:.3f} |  Validation perplexity: {math.exp(validationLoss):7.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea9325",
   "metadata": {},
   "source": [
    "\n",
    "### Translation - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bc9076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation!!!! YESS!!!\n",
    "def translateSentence(inputSentence, srcLanguageField, trgLanguageField, model, device, maxLength = 50000):\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenization\n",
    "    # If input sentence is a string\n",
    "    if isinstance(inputSentence, str):\n",
    "        # Tokenize with spacy\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text.lower() for token in nlp(inputSentence)]\n",
    "    # If input are tokens\n",
    "    else:\n",
    "        # Convert into lower case\n",
    "        tokens = [token.lower() for token in inputSentence]\n",
    "    \n",
    "    \n",
    "    # Tokens are set to '' + token + ''\n",
    "    tokens = [srcLanguageField.init_token] + tokens + [srcLanguageField.eos_token]\n",
    "    \n",
    "    # Convert token into numerical index using src vocab string to index mapping\n",
    "    srcIndexes = [srcLanguageField.vocab.stoi[token] for token in tokens]\n",
    "    \n",
    "    # Convert into tensor and add a dimension (batch size) on the first dimension \n",
    "    srcTensor = torch.LongTensor(srcIndexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Create source mask\n",
    "    srcMask = model.createSrcMask(srcTensor)\n",
    "    \n",
    "    # Encoding\n",
    "    # Source tensor is passed through the encoder\n",
    "    with torch.no_grad():\n",
    "        encoderSrc = model.encoder(srcTensor, srcMask)\n",
    "    \n",
    "    # Init target sequence from trg vocab with regards to the init_token\n",
    "    trgIndexes = [trgLanguageField.vocab.stoi[trgLanguageField.init_token]]\n",
    "    \n",
    "    \n",
    "    # Iterate up to max length\n",
    "    for i in range(maxLength):\n",
    "        # Convert sequence into tensor\n",
    "        trgTensor = torch.LongTensor(trgIndexes).unsqueeze(0).to(device)\n",
    "        # Create padding mask and lookahead mask\n",
    "        trgMask = model.createTrgMask(trgTensor)\n",
    "        \n",
    "        # Decoding\n",
    "        with torch.no_grad():\n",
    "            # Generates output token and attention using the current target sequence and encoded src\n",
    "            output, attention = model.decoder(trgTensor, encoderSrc, trgMask, srcMask)\n",
    "        \n",
    "        # Predicted token, takes token with the highest probability\n",
    "        predictedToken = output.argmax(2)[:,-1].item()\n",
    "        # Add it to target sequence\n",
    "        trgIndexes.append(predictedToken)\n",
    "        \n",
    "        # Break out of the iterative loop if eos token is generated\n",
    "        if predictedToken == trgLanguageField.vocab.stoi[trgLanguageField.eos_token]:\n",
    "            break\n",
    "    \n",
    "    # Indexes are converted back to string\n",
    "    trgTokens = [trgLanguageField.vocab.itos[i] for i in trgIndexes]\n",
    "    \n",
    "    # Return the output\n",
    "    return trgTokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8115a1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28056\\3344266133.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('Model/FYPSeq2SeqModel.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Model/FYPSeq2SeqModel.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e6988b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSequence = Input\n",
    "targetSequence = Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee10a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Translate4MePlz_en2py(src):\n",
    "    src = src.split(\" \")\n",
    "    translation, attention = translateSentence(src, inputSequence, targetSequence, model, device)\n",
    "\n",
    "    print(f'Here is the translation for you kind person : \\n')\n",
    "    print(untokenize(translation[:-1]).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12f2f58f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation for you kind person : \n",
      "\n",
      "num1 =1.5 \n",
      "num2 =6.3 \n",
      "sum =num1 +num2 \n",
      "print (f'Sum: {sum}')\n"
     ]
    }
   ],
   "source": [
    "translateMe = 'Add two numbers'\n",
    "Translate4MePlz_en2py(translateMe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65d4b0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation for you kind person : \n",
      "\n",
      "def var1 (var2 ):\n",
      "    if var2 ==0 :\n",
      "        return True \n",
      "    else :\n",
      "        return False \n"
     ]
    }
   ],
   "source": [
    "translateMe2 = 'Write a python script to generates random numbers between 0 and 9 that are divisible by 3'\n",
    "Translate4MePlz_en2py(translateMe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40d4a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation for you kind person : \n",
      "\n",
      "\n",
      "import var1 \n",
      "\n",
      "var1 =[]\n",
      "\n",
      "var2 =[]\n",
      "for i in range (0 ,len (var1 )):\n",
      "    var2 +=1 \n",
      "\n",
      "for j in range (0 ,len (var1 )):\n",
      "    var2 +=var1 [j ]\n",
      "\n",
      "print (var2 )\n"
     ]
    }
   ],
   "source": [
    "translateMe3 = 'Write a Python program to calculate the average of a list of positive integers and output the result'\n",
    "Translate4MePlz_en2py(translateMe3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "91b42693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation for you kind person : \n",
      "\n",
      "def var1 (var2 ):\n",
      "    for i in range (len (var2 )):\n",
      "        var2 [i ]=var2 [i ]\n",
      "        var2 [i ]=var2 [i ]\n",
      "        while var2 >0 and var2 %2 ==0 :\n",
      "            var2 +=1 \n",
      "            var2 +=1 \n",
      "            var2 [var2 -1 \n",
      "    return var2 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translateMe4 = 'function in Python that prints out the Pascal triangle for a given number of rows'\n",
    "Translate4MePlz_en2py(translateMe4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "00e60bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the translation for you kind person : \n",
      "\n",
      "var1 =10 \n",
      "**3 \n"
     ]
    }
   ],
   "source": [
    "translateMe5 = 'Calculate the volume of a cube'\n",
    "Translate4MePlz_en2py(translateMe5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb76af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
